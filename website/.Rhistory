names(d) <- c("User","Tweets")
return (d)
}
# Plot the table above for the top 20
d<-reactive({d<-toptweeters(  twtList() ) })
output$tweetersplot<-renderPlot ( barplot(head(d()$Tweets, 20), names=head(d()$User, 20), horiz=F, las=2, main="Top Tweeters", col=1) )
output$tweeterstable<-renderTable(head(d(),20))
#TOP 10 HASHTAGS OF USER
tw1 <- reactive({ tw1 = userTimeline(input$user, n = 3200) })
tw <- reactive({ tw = twListToDF(tw1()) })
vec1<-reactive ({ vec1 = tw()$text })
extract.hashes = function(vec){
hash.pattern = "#[[:alpha:]]+"
have.hash = grep(x = vec, pattern = hash.pattern)
hash.matches = gregexpr(pattern = hash.pattern,
text = vec[have.hash])
extracted.hash = regmatches(x = vec[have.hash], m = hash.matches)
df = data.frame(table(tolower(unlist(extracted.hash))))
colnames(df) = c("tag","freq")
df = df[order(df$freq,decreasing = TRUE),]
return(df)
}
dat<-reactive({ dat = head(extract.hashes(vec1()),50) })
dat2<- reactive ({ dat2 = transform(dat(),tag = reorder(tag,freq)) })
p<- reactive ({ p = ggplot(dat2(), aes(x = tag, y = freq)) + geom_bar(stat="identity", fill = "blue")
p + coord_flip() + labs(title = "Hashtag frequencies in the tweets of the tweeter") })
output$tophashtagsplot <- renderPlot ({ p() })
}) #shiny server
#assuming input = Ottawa
a_trends = availableTrendLocations()
woeid = a_trends[which(a_trends$name=="Ottawa"),3]
canada_trend = getTrends(woeid)
trends = canada_trend[1:2]
#To clean data and remove Non English words:
dat <- cbind(trends$name)
dat2 <- unlist(strsplit(dat, split=", "))
dat3 <- grep("dat2", iconv(dat2, "latin1", "ASCII", sub="dat2"))
dat4 <- dat2[-dat3]
dat4
library(shiny)
shinyUI(pageWithSidebar(
headerPanel("Twitter Sentiment Analysis"),
# Getting User Inputs
sidebarPanel(
textInput("searchTerm", "Enter data to be searched with '#'", "#"),
sliderInput("maxTweets","Number of recent tweets to use for analysis:",min=5,max=1000,value=500),
submitButton(text="Analyse")
),
mainPanel(
tabsetPanel(
tabPanel("Top Trending Tweets Today",HTML("<div>Top Trending Tweets according to location</div>"),
selectInput("trendingTable","Choose location to extract trending tweets",c("Worldwide" ,  "Abu Dhabi" ,"Acapulco" , "Accra" ,
"Adana" , "Adela", "Aguascalientes" , "Ahmedabad" ,
"Ahsa" , "Albuquerque" , "Alexandria" , "Algeria" , "Algiers" , "Amman" , "Amritsar" , "Amsterdam",  "Ankara" , "Ansan" ,
"Antalya" , "Antipolo" , "Argentina" ,  "Athens" ,
"Atlanta" ,             "Auckland" ,            "Austin" ,              "Australia" ,           "Austria"  ,            "Bahrain"     ,         "Baltimore"  ,
"Bandung"   ,           "Bangalore" ,           "Bangkok",              "Barcelona" ,           "Barcelona",            "Barquisimeto",         "Barranquilla"  ,
"Baton Rouge" ,         "Bekasi"    ,           "Belarus",              "Belem"     ,           "Belfast"  ,            "Belgium"     ,         "Belo Horizonte",
"Benin City"  ,         "Bergen"    ,           "Berlin" ,              "Bhopal"    ,           "Bilbao"   ,            "Birmingham"  ,         "Birmingham"    ,
"Blackpool"   ,         "Bogota"    ,           "Bologna",              "Bordeaux"  ,           "Boston"   ,            "Bournemouth" ,         "Brasilia"      ,
"Brazil"      ,         "Bremen"    ,           "Brest"  ,              "Brighton"  ,           "Brisbane" ,            "Bristol"     ,         "Bucheon"       ,
"Buenos Aires",         "Bursa"     ,           "Busan"  ,              "Cagayan de Oro" ,      "Cairo"    ,            "Calgary"     ,         "Cali"      ,
"Calocan"     ,         "Campinas"  ,           "Can Tho",              "Canada"    ,           "Canberra"  ,           "Cape Town"   ,         "Caracas"   ,
"Cardiff"     ,         "Cebu City" ,           "Changwon" ,            "Charlotte" ,           "Chelyabinsk" ,         "Chennai"     ,         "Chiba"     ,
"Chicago"     ,         "Chihuahua" ,           "Chile"    ,            "Cincinnati",           "Ciudad Guayana" ,      "Ciudad Juarez",        "Cleveland" ,
"Cologne"     ,         "Colombia"  ,           "Colorado Springs",     "Columbus"  ,           "Concepcion" ,          "Cordoba"      ,        "Cork"      ,
"Coventry"    ,         "Culiacan"  ,           "Curitiba"    ,         "Da Nang"   ,           "Daegu"      ,          "Daejeon"      ,        "Dallas-Ft. Worth" ,
"Dammam"  , "Darwin" ,"Davao City", "Delhi", "Den Haag" , "Denmark" ,"Denver" ,  "Depok" , "Derby" , "Detroit" , "Diyarbakir" , "Dnipropetrovsk" ,"Dominican Republic","Donetsk",
"Dortmund"  ,           "Dresden" ,             "Dubai"         ,       "Dublin"      ,         "Durban"       ,        "Dusseldorf"    ,       "Ecatepec de Morelos",
"Ecuador"       ,       "Edinburgh" ,           "Edmonton"      ,       "Egypt"       ,         "El Paso"      ,        "Eskisehir"     ,       "Essen"    ,
"Faisalabad"    ,       "Fortaleza"  ,          "France"        ,       "Frankfurt"   ,         "Fresno"       ,        "Fukuoka"       ,       "Galway"   ,
"Gaziantep"    ,        "Gdansk"      ,         "Geneva"       ,        "Genoa"       ,         "Germany"      ,        "Ghana"         ,       "Giza"     ,
"Glasgow"      ,        "Goiania"     ,         "Gomel"        ,        "Gothenburg"  ,         "Goyang"       ,        "Greece"        ,       "Greensboro" ,
"Grodno"       ,        "Guadalajara" ,         "Guarulhos"    ,        "Guatemala"   ,         "Guatemala City"  ,     "Guayaquil"     ,       "Gwangju"  ,
"Hai Phong"    ,        "Haifa"       ,         "Hamamatsu"    ,        "Hamburg"     ,         "Hanoi"      ,          "Harrisburg"    ,       "Hermosillo"     ,
"Hiroshima"    ,        "Ho Chi Minh City" ,    "Honolulu"     ,        "Houston"     ,         "Hull"       ,          "Hulu Langat"   ,       "Hyderabad"      ,
"Ibadan"       ,        "Incheon"      ,        "India"        ,        "Indianapolis",         "Indonesia" ,           "Indore"        ,       "Ipoh"           ,
"Ireland"      ,        "Irkutsk"       ,       "Israel"       ,        "Istanbul"    ,         "Italy"     ,           "Izmir"         ,       "Jackson"        ,
"Jacksonville" ,        "Jaipur"        ,       "Jakarta"      ,        "Japan"       ,         "Jeddah"    ,           "Jerusalem"     ,       "Johannesburg"   ,
"Johor Bahru"  ,        "Jordan"        ,       "Kaduna"       ,        "Kajang"      ,         "Kano"      ,           "Kanpur"        ,       "Kansas City"    ,
"Karachi"      ,        "Kawasaki"      ,       "Kayseri"      ,        "Kazan"       ,         "Kenya"     ,           "Khabarovsk"    ,       "Kharkiv"        ,
"Kitakyushu"   ,        "Klang"         ,       "Kobe"         ,        "Kolkata"      ,        "Konya"     ,           "Korea"         ,       "Krakow"         ,
"Krasnodar"    ,        "Krasnoyarsk"   ,       "Kuala Lumpur" ,        "Kumamoto"    ,         "Kumasi"    ,           "Kuwait"        ,       "Kyiv"           ,
"Kyoto" ,               "Lagos"    ,            "Lahore"       ,        "Las Palmas",           "Las Vegas"   ,         "Latvia" ,              "Lausanne"       ,
"Lebanon" ,              "Leeds"   ,             "Leicester",            "Leipzig" ,             "Leon"        ,         "Lille"  ,              "Lima" ,
"Liverpool" ,           "Lodz"     ,            "London"      ,         "Long Beach" ,          "Los Angeles"  ,        "Louisville"       ,    "Lucknow"  ,
"Lviv"       ,          "Lyon"          ,       "Madrid"       ,        "Makassar"    ,         "Makati"      ,         "Malaga"          ,     "Malaysia"  ,
"Manaus"     ,          "Manchester"  ,         "Manila"       ,        "Maracaibo"   ,         "Maracay"   ,           "Marseille"     ,       "Maturin"   ,
"Mecca"       ,         "Medan"      ,          "Medellin"      ,       "Medina"       ,        "Melbourne"  ,          "Memphis"      ,        "Mendoza"    ,
"Merida"       ,        "Mersin"    ,           "Mesa"           ,      "Mexicali"      ,       "Mexico"    ,           "Mexico City" ,         "Miami"       ,
"Middlesbrough" ,       "Milan"    ,            "Milwaukee"       ,     "Minneapolis"    ,      "Minsk"      ,          "Mombasa"    ,          "Monterrey"    ,
"Montpellier"     ,     "Montreal" ,            "Morelia"           ,   "Moscow"           ,    "Multan"    ,           "Mumbai"     ,          "Munich" ,
"Murcia"  ,             "Muscat" ,              "Nagoya"       ,    "Nagpur"            ,   "Nairobi"  ,            "Nantes"    ,           "Naples"          ,
"Nashville" , "Netherlands",  "New Haven" , "New Orleans" , "New York","New Zealand" , "Newcastle", "Nigeria" , "Niigata" ,"Nizhny Novgorod" , "Norfolk", "Norway",
"Nottingham"   ,        "Novosibirsk"      ,    "Odesa"         ,       "Okayama"      ,        "Okinawa"         ,     "Oklahoma City"     ,   "Omaha"    ,
"Oman"          ,       "Omsk"            ,     "Orlando"        ,      "Osaka"        ,        "Oslo"              ,   "Ottawa"           ,    "Pakistan"  ,
"Palembang"      ,      "Palermo"        ,      "Palma"            ,    "Panama"        ,       "Paris"            ,    "Pasig"           ,     "Patna"      ,
"Pekanbaru"       ,     "Perm"          ,       "Perth"           ,     "Peru"           ,      "Petaling"        ,     "Philadelphia"   ,      "Philippines" ,
"Phoenix"    ,          "Pittsburgh"   ,        "Plymouth"  ,           "Poland"          ,     "Port Elizabeth" ,      "Port Harcourt" ,       "Portland"     ,
"Porto Alegre" ,        "Portsmouth"  ,         "Portugal"   ,          "Poznan"           ,    "Preston"       ,       "Pretoria"     ,        "Providence"    ,
"Puebla"        ,       "Puerto Rico"    ,      "Pune"        ,         "Qatar"             ,   "Quebec"       ,        "Queretaro"           , "Quezon City"    ,
"Quito"    ,            "Rajkot"       ,        "Raleigh"     ,         "Ranchi"            ,   "Rawalpindi" ,          "Recife"            ,   "Rennes"         ,
"Richmond"   ,          "Riga"         ,        "Rio de Janeiro",       "Riyadh"      ,         "Rome"       ,          "Rosario"           ,   "Rostov-on-Don"    ,
"Rotterdam"  ,          "Russia"     ,          "Sacramento"    ,       "Sagamihara"  ,         "Saint Petersburg",     "Saitama"         ,     "Salt Lake City"  ,
"Saltillo"     ,        "Salvador"   ,          "Samara"          ,     "San Antonio"   ,       "San Diego"       ,     "San Francisco"   ,     "San Jose"  ,
"San Luis Potosi",      "Santiago"  ,           "Santo Domingo"    ,  "Sao Paulo"      ,      "Sapporo"        ,      "Saudi Arabia"       ,
"Seattle"   ,           "Semarang"      ,       "Sendai"            ,   "Seongnam"        ,     "Seoul"         ,       "Seville"       ,       "Sharjah"   ,
"Sheffield" ,           "Singapore"   ,         "Singapore"         ,   "South Africa"    ,     "Soweto"      ,         "Spain"       ,         "Srinagar"  ,
"St. Louis"  ,          "Stockholm"  ,          "Stoke-on-Trent"     ,  "Strasbourg"       ,    "Stuttgart"  ,          "Surabaya"   ,          "Surat"      ,
"Suwon"        ,        "Swansea"    ,          "Sweden"     ,          "Switzerland"        ,  "Sydney"     ,          "Taguig"     ,          "Takamatsu"    ,
"Tallahassee"  ,        "Tampa"    ,            "Tangerang"  ,          "Tel Aviv"           ,  "Thailand" ,            "Thane"    ,            "Thessaloniki" ,
"Tijuana"        ,      "Tokyo"    ,            "Toluca"       ,        "Toronto"   ,           "Toulouse"          ,   "Tucson"   ,            "Turin"          ,
"Turkey"    ,           "Turmero"     ,         "Ufa"           ,       "Ukraine"    ,          "Ulsan"            ,    "United Arab Emirates", "United Kingdom"   ,
"United States" ,       "Utrecht"   ,           "Valencia"      ,       "Valencia"   ,          "Valparaiso"     ,      "Vancouver"   ,         "Venezuela"      ,
"Vienna"      ,         "Vietnam"   ,           "Virginia Beach"  ,     "Vladivostok"  ,        "Volgograd"      ,      "Voronezh"    ,         "Warsaw"  ,
"Washington"  ,         "Winnipeg",  "Wroclaw"      ,        "Yekaterinburg",        "Yokohama"  ,  "Yongin",
"Zamboanga City" ,      "Zapopan",              "Zaporozhye"       ,    "Zaragoza"       ,      "Zurich"  ), selected = "Worldwide", selectize = FALSE),
submitButton(text="Search"),HTML("<div><h3> The table below shows the top trending
hashtags on Twitter of the location you have chosen. These are the hot topics today! </h3></div>"),
tableOutput("trendtable"),
HTML
("<div> </div>")),
tabPanel("WordCloud",HTML("<div><h3>Most used words associated with the hashtag</h3></div>"),plotOutput("word"),
HTML
("<div><h4> A word cloud is a visual representation of text data, typically used to depict keyword metadata (tags) on websites, or to visualize free form text.
This format is useful for quickly perceiving the most prominent terms and for locating a term alphabetically to determine its relative prominence.
</h4></div>")),
tabPanel("Histogram",HTML
("<div><h3> Histograms graphically depict the positivity or negativity of peoples' opinion about of the hashtag
</h3></div>"), plotOutput("histPos"), plotOutput("histNeg"), plotOutput("histScore")
),
tabPanel("Pie Chart",HTML("<div><h3>Pie Chart</h3></div>"), plotOutput("piechart"),HTML
("<div><h4> A pie chart is a circular statistical graphic, which is divided into slices to illustrate the sentiment of the hashtag. In a pie chart, the arc length
of each slice (and consequently its central angle and area), is proportional to the quantity it represents.</h4></div>")
),
tabPanel("Table",HTML( "<div><h3> Depicting sentiment in a tablular form on a scale of 5 </h3></div>"), tableOutput("tabledata"),
HTML ("<div><h4> The table depicts the sentiment (positive, negative or neutral) of the tweets
associated with the search hashtag by showing the score for each type of sentiment. </h4></div>")),
tabPanel("Top tweeters",HTML
("<div><h3> Top 20 tweeters of hastag</h3></div>"),plotOutput("tweetersplot"), tableOutput("tweeterstable")),
tabPanel("Top Hashtags of User",textInput("user", "Enter User Name", "@"),submitButton(text="Search"),plotOutput("tophashtagsplot"),HTML
("<div> <h3>Hastag frequencies in the tweets of the tweeter</h3></div>"))
)#end of tabset panel
)#end of main panel
))#end of shinyUI
libary(shiny)
library(shiny)
runApp("Front End");
q()
install.packages("randomForest")
install.packages("randomForest")
library(ROAuth)
library(twitteR)
consumer_key <-  "qWdbUaJbNHEQCyx53dPNExxiv"
consumer_secret <- "GVpzSznWu9fbLL9dVTiDaFi373bkSedwOo0P00yPyuu1e9jQCe"
access_token <- "541416681-J1nFncJnQJdFyz0e89pcxVAy7IwGrJ2pA0jt2ley"
access_secret <- "Xy68VcrwLPkU27184k2JnUraH0CnMbtH3snLzY2C9nMxE"
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem") #downloads the certificate
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
cred <- OAuthFactory$new(consumerKey=consumer_key,
consumerSecret=consumer_secret,
requestURL='https://api.twitter.com/oauth/request_token',
accessURL='https://api.twitter.com/oauth/access_token',
authURL='https://api.twitter.com/oauth/authorize')
cred$handshake(cainfo="cacert.pem")
trump.tweets = searchTwitter("Trump", n=100)
df <- do.call("rbind", lapply(trump.tweets, as.data.frame))
df$text <- sapply(df$text,function(row) iconv(row, "latin1", "ASCII", sub=""))
df$text = gsub("(f|ht)tp(s?)://(.*)[.][a-z]+", "", df$text) #remove URL
sample <- df$text
head(sample)
trump.tweets = searchTwitter("Trump", n=100)
df <- do.call("rbind", lapply(trump.tweets, as.data.frame))
df$text <- sapply(df$text,function(row) iconv(row, "latin1", "ASCII", sub=""))
df$text = gsub("(f|ht)tp(s?)://(.*)[.][a-z]+", "", df$text) #remove URL
sample <- df$text
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
list=lapply(sentences, function(sentence, pos.words, neg.words)
{
sentence = gsub('[[:punct:]]',' ',sentence)
sentence = gsub('[[:cntrl:]]','',sentence)
sentence = gsub('\\d+','',sentence)  #removes decimal number
sentence = gsub('\n','',sentence)    #removes new lines
sentence = tolower(sentence)
word.list = str_split(sentence, '\\s+')
words = unlist(word.list)  #changes a list to character vector
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
pp = sum(pos.matches)
nn = sum(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
list1 = c(score, pp, nn)
return (list1)
}, pos.words, neg.words)
score_new = lapply(list, `[[`, 1)
pp1 = lapply(list, `[[`, 2)
nn1 = lapply(list, `[[`, 3)
scores.df = data.frame(score = score_new, text=sentences)
positive.df = data.frame(Positive = pp1, text=sentences)
negative.df = data.frame(Negative = nn1, text=sentences)
list_df = list(scores.df, positive.df, negative.df)
return(list_df)
}
table
table1
posSc=table_final$Positive
negSc=table_final$Negative
table_final$PosPercent = posSc/ (posSc+negSc)
pp = table_final$PosPercent
pp[is.nan(pp)] <- 0
table_final$PosPercent = pp
table_final$NegPercent = negSc/ (posSc+negSc)
nn = table_final$NegPercent
nn[is.nan(nn)] <- 0
table_final$NegPercent = nn
table_final
#Histogram
hist(table_final$Positive, col=rainbow(10))
hist(table_final$Negative, col=rainbow(10))
hist(table_final$Score, col=rainbow(10))
#Pie
slices <- c(sum(table_final$Positive), sum(table_final$Negative))
labels <- c("Positive", "Negative")
library(plotrix)
#pie(slices, labels = labels, col=rainbow(length(labels)), main="Sentiment Analysis")
pie3D(slices, labels = labels, col=rainbow(length(labels)),explode=0.00, main="Sentiment Analysis")
library(randomForest)
data1 <- read.csv(positive-words.txt, header = TRUE)
head(data1)
str(data1)
summary(data1)
set.seed(100)
train <- sample(nrow(data1), 0.7*nrow(data1), replace = FALSE)
TrainSet <- data1[train,]
ValidSet <- data1[-train,]
summary(TrainSet)
summary(ValidSet)
model1 <- randomForest(Condition ~ ., data = TrainSet, importance = TRUE)
model2 <- randomForest(Condition ~ ., data = TrainSet, ntree = 500, mtry = 6, importance = TRUE)
# Predicting on train set
predTrain <- predict(model2, TrainSet, type = "class")
# Checking classification accuracy
table(predTrain, TrainSet$Condition)
# Predicting on Validation set
predValid <- predict(model2, ValidSet, type = "class")
# Checking classification accuracy
mean(predValid == ValidSet$Condition)
table(predValid,ValidSet$Condition)
# To check important variables
importance(model2)
varImpPlot(model2)
library(randomForest)
data1 <- read.csv(positive-words.txt, header = TRUE)
head(data1)
str(data1)
summary(data1)
set.seed(100)
train <- sample(nrow(data1), 0.7*nrow(data1), replace = FALSE)
library(randomForest)
table1 <- read.csv(positive-words.txt, header = TRUE)
table2 <- read.csv(negative-words.txt, header = TRUE)
head(data1)
str(data1)
summary(data1)
set.seed(100)
train <- sample(nrow(data1), 0.7*nrow(data1), replace = FALSE)
q()
install.packages("flexdashboard")
install.packages("flexdashboard")
library(flexdashboard)
library(knitr)
library(DT)
install.packages("DT")
data <- read.csv(("~/Desktop/Books/VehicleFailure.csv"))
data <- read.csv(("~/Desktop/Books/VehicleFailure.csv"))
data <- read.csv(("~/Desktop/Books"))
data <- read.csv(("~/Desktop/data/VehicleFailure.csv"))
data <- read.csv("~/Desktop/data/VehicleFailure.csv")
library(flexdashboard)
library(knitr)
library(DT)
library(rpivotTable)
library(ggplot2)
library(plotly)
install.packages("plotly")
install.packages("plotly")
install.packages("plotly")
install.packages("plotly")
install.packages("plotly")
install.packages("dplyr")
install.packages("dplyr")
install.packages("openintro")
install.packages("highcharter")
install.packages("highcharter")
View(hash.matches)
rm(list=ls())
library(flexdashboard)
library(knitr)
library(DT)
library(rpivotTable)
library(ggplot2)
library(plotly)
update.packages()
library(flexdashboard)
update.packages()
data <- read.csv("~/Desktop/Books/data/VehicleFailure.csv")
library(flexdashboard)
library(knitr)
library(DT)
library(rpivotTable)
library(ggplot2)
library(plotly)
library(dplyr)
library(openintro)
library(highcharter)
data <- read.csv("~/Desktop/Books/data/VehicleFailure.csv")
getwd ()
data <- read.csv(file="VehicleFailure.csv",head=TRUE,sep",")
getwd ()
setwd("C:/Users/Anirban/Desktop/Books/data")
getwd()
list.files()
data <- read.csv("~/Desktop/Books/data/VehicleFailure.csv")
f <- file.choose(C:/Users/Anirban/Desktop/Books/data/VehicleFailure.csv)
data <- read.csv("C:/Users/Anirban/Desktop/Books/data/VehicleFailure.csv")
Column {data-width=650}
data <- read.csv("C:/Users/Anirban/Desktop/Books/data/VehicleFailure.csv")
Column {data-width=650}
data <- read.csv("C:/Users/Anirban/Desktop/Books/data/VehicleFailure.c")
data <- read.csv("C:/Users/Anirban/Desktop/Books/data/VehicleFailure.csv")
Column {data-width=650}
str(data)
gauge(round(mean(data$lc),
digits = 2),
min = 0,
max = 350,
gaugeSectors(success = c(0, 150),
warning = c(150,240),
danger = c(240, 350),
colors = c('green', 'yellow', 'red'))))
gauge(round(mean(data$lc),
digits = 2),
min = 0,
max = 350,
gaugeSectors(success = c(0, 150),
warning = c(150, 240),
danger = c(240, 350),
colors = c('green', 'yellow', 'red')))
p1 <- data %>%
group_by(State) %>%
summarise(count = n()) %>%
plot_ly(x = ~State,
y = ~count,
color = rainbow(51),
type = 'bar') %>%
layout(xaxis = list(title = "Failures By State"),
yaxis = list(title = "Count"))
p1
p2 <- data %>%
group_by(State) %>%
summarise(count = n()) %>%
filter(count>50) %>%
plot_ly(labels = ~State,
values = ~count,
marker = list(colors = mycolors)) %>%
add_pie(hole = 0.2) %>%
layout(xaxis = list(zeroline = F,
showline = F,
showticklabels = F,
showgrid = F),
yaxis = list(zeroline = F,
showline = F,
showticklabels=F,
showgrid=F))
p2 <- data %>%
group_by(State) %>%
summarise(count = n()) %>%
filter(count>50) %>%
plot_ly(labels = ~State,
values = ~count,
marker = list(colors = mycolors)) %>%
add_pie(hole = 0.2) %>%
layout(xaxis = list(zeroline = F,
showline = F,
showticklabels = F,
showgrid = F),
yaxis = list(zeroline = F,
showline = F,
showticklabels=F,
showgrid=F))
p3 <- plot_ly(data,
x = ~fm,
y = ~Mileage,
text = paste("FM:", data$fm,
"Mileage:",
data$Mileage),
type = "bar") %>%
layout(xaxis = list(title="FM"),
yaxis = list(title = "Failure Mileage"))
p3
rpivotTable(data,
aggregatorName = "Count",
cols= "fm",
rows = "State",
rendererName = "Heatmap")
data %>%
group_by(State) %>%
ggvis(~State, ~lc, fill = ~State) %>%
layer_boxplots()
library(flexdashboard)
library(knitr)
library(DT)
library(rpivotTable)
library(ggplot2)
library(plotly)
library(dplyr)
library(openintro)
library(highcharter)
library(ggvis)
install.packages("ggvis")
install.packages("ggvis")
p1 <- data %>%
group_by(State) %>%
summarise(count = n()) %>%
plot_ly(x = ~State,
y = ~count,
color = "blue",
type = 'bar') %>%
layout(xaxis = list(title = "Failures By State"),
yaxis = list(title = 'Count'))
p1
p2 <- data %>%
group_by(State) %>%
summarise(count = n()) %>%
filter(count>50) %>%
plot_ly(labels = ~State,
values = ~count,
marker = list(colors = mycolors)) %>%
add_pie(hole = 0.2) %>%
layout(xaxis = list(zeroline = F,
showline = F,
showticklabels = F,
showgrid = F),
yaxis = list(zeroline = F,
showline = F,
showticklabels=F,
showgrid=F))
library(flexdashboard)
library(knitr)
library(DT)
library(rpivotTable)
library(ggplot2)
library(plotly)
library(dplyr)
library(openintro)
library(highcharter)
library(ggvis)
p2 <- data %>%
group_by(State) %>%
summarise(count = n()) %>%
filter(count>50) %>%
plot_ly(labels = ~State,
values = ~count,
marker = list(colors = color)) %>%
add_pie(hole = 0.2) %>%
layout(xaxis = list(zeroline = F,
showline = F,
showticklabels = F,
showgrid = F),
yaxis = list(zeroline = F,
showline = F,
showticklabels=F,
showgrid=F))
p2 <- data %>%
group_by(State) %>%
summarise(count = n()) %>%
filter(count>50) %>%
plot_ly(labels = ~State,
values = ~count,
marker = list(colors = mycolors)) %>%
add_pie(hole = 0.2) %>%
layout(xaxis = list(zeroline = F,
showline = F,
showticklabels = F,
showgrid = F),
yaxis = list(zeroline = F,
showline = F,
showticklabels=F,
showgrid=F))
mycolors <- c("blue", "#FFC125", "darkgreen", "darkorange")
p2 <- data %>%
group_by(State) %>%
summarise(count = n()) %>%
filter(count>50) %>%
plot_ly(labels = ~State,
values = ~count,
marker = list(colors = mycolors)) %>%
add_pie(hole = 0.2) %>%
layout(xaxis = list(zeroline = F,
showline = F,
showticklabels = F,
showgrid = F),
yaxis = list(zeroline = F,
showline = F,
showticklabels=F,
showgrid=F))
p2
